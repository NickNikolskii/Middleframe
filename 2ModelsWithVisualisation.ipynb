{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Middle Frame Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Preparaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Autoencoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear model\n",
    "class autoencoder_lin(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder_lin, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            View((-1, 28*28)),\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh(),\n",
    "            View((-1, 1, 28, 28)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional model\n",
    "class autoencoder_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder_conv, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "image_folder = './data'\n",
    "\n",
    "# dataset = ImageFolder('./data', trans..=...)\n",
    "dataset = MNIST(image_folder, download=True, transform=img_transform)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "data_iter = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter_train = DataLoader(X_train, batch_size = batch_size, shuffle = True)\n",
    "data_iter_test = DataLoader(X_test, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "train_and_test = (data_iter_train, data_iter_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = autoencoder_conv()#.cuda()\n",
    "model_lin = autoencoder_lin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "testdataset = [dataset[1][0].reshape(1,28,28),\n",
    "               dataset[3][0].reshape(1,28,28),\n",
    "               dataset[5][0].reshape(1,28,28),\n",
    "               dataset[7][0].reshape(1,28,28),\n",
    "               dataset[2][0].reshape(1,28,28),\n",
    "               dataset[0][0].reshape(1,28,28),\n",
    "               dataset[13][0].reshape(1,28,28),\n",
    "               dataset[38][0].reshape(1,28,28),\n",
    "               dataset[17][0].reshape(1,28,28),\n",
    "               dataset[4][0].reshape(1,28,28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_from(data, size, n_vis):\n",
    "    grid = []\n",
    "    for j in range(n_vis):\n",
    "        el = data[j].reshape(*size)\n",
    "        grid.append(el)\n",
    "        \n",
    "    return torchvision.utils.make_grid(grid)\n",
    "    writer.add_image(\"Training data\", temp, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input, output, testdataset, losses, epoch):\n",
    "    mean_te_loss, mean_tr_loss = losses\n",
    "    temp = create_grid_from(input, (1,28,28), 8)\n",
    "    \n",
    "    writer.add_image(\"Training data\", temp, epoch)\n",
    "    \n",
    "    temp = create_grid_from(output, (1,28,28), 8)\n",
    "\n",
    "    test_output = []\n",
    "    for img in testdataset:\n",
    "        im = img.view(1,1,28,28)\n",
    "        test_output.append(model_conv(im))\n",
    "        \n",
    "    temp2 = create_grid_from(test_output, (1,28,28), 10)\n",
    "    \n",
    "    writer.add_image(\"Model Test Dataset\", temp2, epoch)\n",
    "    writer.add_image(\"Output\", temp, epoch)\n",
    "    writer.add_scalar(\"Loss/Train\", mean_tr_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Test\", mean_te_loss, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_and_test, num_epochs = 100, learning_rate = 1e-3):\n",
    "    \n",
    "    data_iter_train, data_iter_test = train_and_test\n",
    "\n",
    "    \n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "        \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        n_tr = 0\n",
    "        total_tr_loss = 0\n",
    "        for batch in data_iter_train:\n",
    "            imgs, _ = batch\n",
    "\n",
    "            input = imgs\n",
    "            output = model(input)\n",
    "                    \n",
    "            loss = loss_func(output, input)\n",
    "        \n",
    "            total_tr_loss += loss.item()\n",
    "            n_tr += 1\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        n_te = 0\n",
    "        total_te_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in data_iter_test:\n",
    "                imgs, _ = batch\n",
    "                \n",
    "                input = imgs\n",
    "                output = model(imgs)\n",
    "        \n",
    "                loss = loss_func(output, input)\n",
    "                total_te_loss += loss.item()\n",
    "                n_te += 1\n",
    "        \n",
    "        mean_te_loss = total_te_loss/n_te\n",
    "        mean_tr_loss = total_tr_loss/n_tr\n",
    "        print('epoch [{}/{}], loss:{:.4f}'\n",
    "              .format(epoch + 1, num_epochs, total_te_loss))\n",
    "        \n",
    "        losses = (mean_te_loss, mean_tr_loss)\n",
    "        \n",
    "        visualize(input, output, testdataset, losses, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1], loss:10.2357\n"
     ]
    }
   ],
   "source": [
    "train(model_conv, train_and_test, num_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1], loss:8.3469\n"
     ]
    }
   ],
   "source": [
    "train(model_lin, train_and_test, num_epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Loading And Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_conv.state_dict(), './sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model, './sim_autoencoder.pth')\n",
    "model.load_state_dict(torch.load('./sim_autoencoder.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying to Images (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forshow(img):\n",
    "    return transforms.ToPILImage(mode='L')(img.reshape(28,28))\n",
    "\n",
    "def encode(img_from_dataset):\n",
    "    norm_img = img_from_dataset.reshape(28*28)\n",
    "    return model.encoder(norm_img)\n",
    "\n",
    "def decode(encoding):\n",
    "    dec_img = model.decoder(encoding)\n",
    "    return dec_img\n",
    "\n",
    "def midFrame(img1, img2):\n",
    "    return decode((encode(img1) + encode(img2))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = dataset[0][0]\n",
    "im2 = dataset[6][0]\n",
    "\n",
    "forshow(im1).show()\n",
    "forshow(decode(encode(im1))).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid1 = midFrame(im1, im2)\n",
    "\n",
    "mid2 = midFrame(mid1,im2)\n",
    "\n",
    "mid3 = midFrame(im1, mid1)\n",
    "for i in [im1, mid3, mid1, mid2, im2]:\n",
    "    forshow(i).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = dataset[0]\n",
    "\n",
    "my_img = model(img.reshape(28*28))\n",
    "my_img = my_img.reshape(1,28,28)\n",
    "\n",
    "results = transforms.ToPILImage(mode='L')(my_img)\n",
    "results.show()\n",
    "\n",
    "#output[0]\n",
    "#image = output.cpu().numpy()[0]\n",
    "#image = np.transpose(image, (1,2,0))\n",
    "#plt.matshow(image)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = dataset[0]\n",
    "results = transforms.ToPILImage(mode='L')(img.reshape(1,28,28)) \n",
    "results.show()\n",
    "\n",
    "img2 = model(img.reshape(28*28))\n",
    "results2 = transforms.ToPILImage(mode='L')(img2.reshape(1,28,28)) \n",
    "results2.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show middle\n",
    "img, _ = dataset[0]\n",
    "img2, _ = dataset[1]\n",
    "enc1 = model.encoder(img.reshape(28*28))\n",
    "enc2 = model.encoder(img2.reshape(28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toPILimg(img).show()\n",
    "toPILimg(img2).show()\n",
    "result = (enc1+enc2)/2\n",
    "decode(result).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img5_2, _ = dataset[11]\n",
    "img5_1, _ = dataset[0]\n",
    "toPILimg(img5_1).show()\n",
    "toPILimg(img5_2).show()\n",
    "midFrame(img5_1, img5_2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
